## Master Practical of Image and Video Synthesis  <br><sub>**Research of Diversity of SiT**</sub>
[Our Report Paper](https://arxiv.org/pdf/2401.08740.pdf)

![SiT samples](visuals/visual.png)

This repository extends the original [Scalable Interpolant Transformer (SiT)](https://arxiv.org/abs/2401.08740) project to **systematically evaluate the diversity** of generated images using various perceptual and statistical metrics. Our practical focuses on **benchmarking and analyzing SiT under different sampling settings** (SDE/ODE, CFG, noise levels, etc.), and includes tools for evaluating:

- **FID / sFID**
- **Inception Score**
- **Precision & Recall**
- **LPIPS (perceptual diversity)**
- **DreamSim Distance**
- **DINOv2 Similarity**
- **CLIP-based Feature Diversity**

## âœ… Project Goals

**We aim to answer:**

> 1. How do different sampling settings and interpolation parameters affect the diversity of samples generated by SiT?
> 2. 
> 3. 

To achieve this, we implemented a comprehensive evaluation pipeline that measures both **intra-class** and **inter-class** diversity.


---
## ðŸ“‚ Folder Structure

<summary><strong>ðŸ“‚ Folder Structure</strong></summary>

```text
â”œâ”€â”€ SiT         # Original Implementation of SiT
â”œâ”€â”€ diversity_metrics/      
â”‚   â”œâ”€â”€ compute_fid.py  
â”‚   â”œâ”€â”€ eval.py  
â”‚   â””â”€â”€ metrics.py   
â”œâ”€â”€ validation_loss/               
â””â”€â”€ vis/               
        
```
---


## ðŸ”§ Setup

Clone the repo and create the environment:

```bash
git clone https://github.com/willisma/SiT.git
cd SiT
conda env create -f environment.yml
conda activate SiT

# Generate samples across multiple classes
torchrun --nproc_per_node=4 sample_ddp.py ODE --model SiT-XL/2 --num-fid-samples 10000

# Compute metrics from saved samples
python diversity_metrics/run_metrics.py --input-dir path/to/samples

##Visualizing Diversity
python diversity_metrics/vis_intra.py --csv-dir results/metrics --save-dir outputs/
```
---


## Experiment Results

NEED TO BE ADDED
